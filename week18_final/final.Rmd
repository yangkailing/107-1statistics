---
title: "final"
author: "b06208016楊鎧綾"
date: "January 9, 2019"
output: html_document
---
#1
##1.4
###(1)
<br/>step.1 
<br/>$H_0:$ region have no relationship with use social networking, they are independent 
<br/>$H_a:$ region have relationship with use social networking, they are dependent

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5
```{r}
use=c(264,410,287,961)
not=c(54,122,264,440)
TOTAL=c(318,532,551,1401)
a=data.frame(use,not,TOTAL,row.names = c('region_a','region_b','region_c','total'))
a
```

<br/>calculate the chi-squared is 118.1388
```{r}
exp_use=c((a[1,3]*a[4,1]/a[4,3]),(a[2,3]*a[4,1]/a[4,3]),(a[3,3]*a[4,1]/a[4,3]))
exp_not=c((a[1,3]*a[4,2]/a[4,3]),(a[2,3]*a[4,2]/a[4,3]),(a[3,3]*a[4,2]/a[4,3]))
exp=data.frame(exp_use,exp_not,row.names = c('region_a','region_b','region_c' ))
exp
a=a[1:3,1:2];a
chi=(a-exp)^2/exp;chi
chi=sum(chi)
chi
```
<br/>step.3 find the p-value is 0
```{r}
nrow=3
ncol=2
df=(nrow-1)*(ncol-1)
p.value=1-pchisq(chi,df=df)
p.value
```
<br/>step.4 under 95% confidence level the alpha=0.05,**the p-value is smaller than alpha, so we can reject null hypothesis**
<br/>step.5 **so we can say that region have relationship with use social networking, they are dependent**

###(2)
<br/>data in region c
```{r}
groups=c("use","notuse","total")
observe=c(287,264,551)
expected=c((1/2)*551,(1/2)*551,551)
a=data.frame(groups,observe,expected)
a
```
<br/>step.1 
<br/>$H_0:$ the percentage of using social networking sites or not is equal $p_1= p_2$
<br/>$H_a:$ the percentage of using social networking sites or not is not equal$p_1 \neq p_2$
<br/>p means the percentage of using social networking sites or not

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5,we calculate the chi-square is 0.9600726
```{r}
c=a[1:2,2]
exp=a[1:2,3]
chi=((c-exp)^2)/exp
chi=sum(chi)
chi
```

<br/>step.3<br/>the degree of freedom is 1<br/>the p-value is  0.3271686
```{r}
k=2
df=k-1;df
p.value=1-pchisq(chi,df=df)
p.value
```

<br/>step.4 under the confidence level of 95% we get the $\alpha=0.05$ ,**the p-value is larger than alpha, it is not significant, so we cannot reject null hypothesis**
<br/>step.5 **so we can say that the percentage of using social networking sites or not is equal**

##1.5
###(1)
```{r}
weight = c(176,212,188,206,200,184,193,209,
           187,193,184,198,210,199,180,195,
           164,203,180,187,223,196,189,211)
program = c("pr1", "pr1", "pr1", "pr1", "pr1", "pr1", "pr1","pr1",
            "pr2", "pr2", "pr2", "pr2", "pr2", "pr2", "pr2", "pr2",
            "pr3", "pr3", "pr3", "pr3","pr3", "pr3", "pr3", "pr3")
month=c("month1","month1","month1","month1","month2","month2","month2","month2",
        "month1","month1","month1","month1","month2","month2","month2","month2",
        "month1","month1","month1","month1","month2","month2","month2","month2"
        )
program = factor(program, levels = c("pr1", "pr2", "pr3"))
month = factor(month, levels = c("month1", "month2"))
```
<br/>step.1 
<br/>$H_0:$ there are no difference between salesperson, that is $\mu_1 = \mu_2 = \mu_3$
<br/>$H_a:$ there are difference between salesperson, that is $\mu_1 \neq \mu_2 \neq \mu_3$(at least one of them is different from others)
<br/>$\mu$ means the mean of the earning of a salesperson 

<br/>step.2 the data do not have outlier and extreme skewed, <br/>and the max sd is smaller than two times the min sd, we can calculate the f-value which is 0.079

```{r}
boxplot(weight ~ program, 
        main = "earning of a salesperson ", cex.main = 1.6)
sd1=sd(c(176,212,188,206,200,184,193,209))
sd2=sd(c(187,193,184,198,210,199,180,195))
sd3=sd(c(164,203,180,187,223,196,189,211))
sd1;sd2;sd3
```

<br/>step.3 as the data shows the p-value is 0.924
```{r}
aa = aov(weight ~ program)
summary(aa)
```
<br/>step.4 under 95% confidence level $\alpha=0.05$, the p-value is larger than alpha, so we cannot reject $H_0$
<br/>step.5 **we can say that there are no difference between salesperson**

###(2)
<br/>step.1 
<br/>$H_0:$ the weekly earnings are not related to either salesperson or months 
<br/>$H_a:$ the weekly earnings are related to either salesperson or months

<br/>step.2 the data do not have outlier and extreme skewed, <br/>and the max sd is smaller than two times the min sd,as the first part(1) show <br/>we can calculate the f-value of interaction which is 1.265
<br/>step.3 as the data shows the p-value is 0.306
<br/>step.4 under 95% confidence level $\alpha=0.05$, the p-value is larger than alpha(no matter it is salesperson, month, or interaction), so we cannot reject $H_0$
<br/>step.5 **we can say that the weekly earnings are not related to either salesperson or months **
```{r}
twoway = aov(weight ~ program + month + program:month)
summary(twoway)
```
##1.1
###(1)
```{r}
heightfoot=read.csv("heightfoot.csv",sep=",",header=T) #read csv
heightfoot=na.omit(heightfoot)#DELETE NA
```
```{r}
height=heightfoot$height
foot.length=heightfoot$foot.length
RESULTS=lm(foot.length~height)
plot(foot.length~height,pch=16,cex=1,col="navy",main="foot.length vs height",xlab="height(inches)",ylab="foot.length(cm)")
abline(RESULTS,col="red")
```
<br/>as the plot shows it **might be linear**,<br/>and it is positive direction,<br/>it's variation is big, because it is vary from average pattern,<br/>it **do not have outliers**,<br/>the difference of male and female is that **female is almost shorter than male even though their parents' height is the same**, but both of male and female have linear positive pattern
###(2)
```{r}
cor.test(height,foot.length)
```
```{r}
height_cm=2.54*height
cor.test(height_cm,foot.length)
```
<br/>the correlation coefficient is 0.563, 不管單位為何，因為它只是看兩者的相關性

###(3)
```{R}
#residuals vs x
res=RESULTS$res
plot(res~height,pch=16,cex=1,col="gold3",main="residual vs height",xlab="height(inches)",ylab="residual",
     cex.main=2,cex.lab=1.2)

abline(h=0,col="red")
```
<br/>if we define that residual bigger than three is outlier, there is one outlier which the height is 84
```{r}
newheightfoot=heightfoot[-28,]
height_n=newheightfoot$height
foot.length_n=newheightfoot$foot.length
cor.test(height_n,foot.length_n)
```
<br/>the correlation coefficient is 0.7577219,which is higher than part(2), because we remove the outlier who is far away from the path, so the correlation of two variable will be higher

#2
###(1)
```{r}
metro=read.csv("metro.csv",sep=",",header=T) #read csv
metro=na.omit(metro)#DELETE NA
```
```{r}
distance=metro$distance
price=metro$price
RESULTS=lm(price~distance)
coeff=RESULTS$coefficients
coeff
```
<br/>the  simple linear regression is **price=-0.8286distance+70.4923**


###(2)
<br/>step.1
<br/>$H_0:\beta_1 = 0$
<br/>$H_a:\beta_1 \ne 0$
<br/>$\beta_1$ means the slope of regression line of population which is infered from sample

<br/>step.2  condition: it seems to be linear and donot have outlier,for all x the sd is the same, and the distribution of y is normal distribution, and observation are independent,so we continue the hypothesis test
```{r}
RESULTS=lm(price~distance)
summary(RESULTS)
```
<br/>calculate t-score is -4.168 (by the table above)
<br/>step.3 the p-value is 6.83e-05(by the table above)
<br/>step.4 under the confidence level of 95% , $\alpha=0.05$, the p-value is smaller than 0.05, so we can reject $H_0$, **it is statistically significant**
<br/>step.5 we can say that $\beta_1$ is different from 0,the x variable and y variable has relationship

###(3)
```{r}
#draw the scatter plot
##y vs x
RESULTS=lm(price~distance)
plot(price~distance,pch=16,cex=1,col="navy",
     main="price vs distance",xlab="distance",ylab="price",cex.main=2,cex.lab=1.2)
abline(RESULTS,col="red")
```
```{R}
#residuals vs x
res=RESULTS$res
plot(res~distance,pch=16,cex=1,col="gold3",
     main="residual vs distance",xlab="distance",ylab="residuals",
     cex.main=2,cex.lab=1.2)

abline(h=0,col="red")
```
```{R}
#histogram of residuals
hist(res,breaks=20,border="white",col="olivedrab3",
     main="histogram of residuals", xlab="residuals",
     cex.main=2,cex.lab=1.2)
```
**<br/>by those plot we can see that <br/>1.it is linear(first plot)<br/>2.it do not have outlier(first plot)<br/>3.by the second plot, we can see that the deviation is almostly the same, it do not change depend on explanatory variable<br/>4.by the histogram we can se that it is almost normal distribution and do not have outlier or extreme skewed<br/>5.we assume that two variable are independent, but exactly we don't know**

###(4)
```{r}
#PI
PI=predict(RESULTS,data.frame(distance=c(50)),interval="prediction",level=0.95);PI

#CI
CI=predict(RESULTS,data.frame(distance=c(50)),interval="confidence",level=0.95);CI
```
<br/>the PI means under the confidence level of 95%,if we pick a y under x=specific, it will have the  probability of 95% to be in the interval<br/>,also means 95% of population y might be in the interval,**y的可能範圍,the PI is (-21.3,79.4)**

<br/>the CI means under the confidence level of 95%, if we sample a lot of time as x=specific and calculate a mean, the mean would have the probability of 95% to be in the interval,**E(y)的可能範圍, the CI is (23.7,34.5)**
<br/>**雖然因為是個體，照理講應該選擇用PI才能代表所有合理的價格範圍，<br/>但由於房仲做過很多，因此極端值不易被他接受，所以用CI來找出一般大家成交價平均的範圍是比較可行的**

#3
###(1)
```{r}
weight = c(17,19,15,17,
           25,22,28,
           19,21,19,17)
program = c("pr1", "pr1", "pr1", "pr1", 
            "pr2", "pr2", "pr2", 
            "pr3", "pr3", "pr3", "pr3")
program = factor(program, levels = c("pr1", "pr2", "pr3"))
```
<br/>step.1 
<br/>$H_0:$ there are no difference between regions, that is $\mu_1 = \mu_2 = \mu_3$
<br/>$H_a:$ there are difference between regions, that is $\mu_1 \neq \mu_2 \neq \mu_3$(at least one of them is different from others)
<br/>$\mu$ means the mean of the renting time of a region 

<br/>step.2 the data do not have outlier and extreme skewed, <br/>and the max sd is smaller than two times the min sd, we can calculate the f-value which is 13.52

```{r}
boxplot(weight ~ program, 
        main = "renting time among regions", cex.main = 1.6)
sd1=sd(c(17,19,15,17))
sd2=sd(c(25,22,28))
sd3=sd(c(19,21,19,17))
sd1;sd2;sd3
```

<br/>step.3 as the data shows the p-value is 0.00272
```{r}
aa = aov(weight ~ program)
summary(aa)
```
<br/>step.4 under 95% confidence level $\alpha=0.05$, the p-value is smaller than alpha, so we can reject $H_0$
<br/>step.5 **we can say that depend on different rejions the renting time of bike might be different**

###(2)
<br/>the sample is small, but it is not extreme skewed and do not have outlier, so we can calculate the confidence interval
```{r}
group2=c(25,22,28)
mean=mean(group2)
sd=sd(group2)
t=qt(0.025,lower.tail = F,df=3-1)
mean-t*sd/sqrt(3)
mean+t*sd/sqrt(3)
```
<br/>**the 95% confidence interval of mean is (17.54,32.45)**

#4
###(1)
<br/>step.1 
<br/>$H_0:$ 支持傾向在不同區域沒有差異
<br/>$H_a:$ 支持傾向在不同區域有差異


<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5
```{r}
blue=c(28,26,23,26,103)
green=c(30,25,38,22,115)
white=c(20,22,15,25,82)
TOTAL=c(78,73,76,73,300)
a=data.frame(blue,green,white,TOTAL,row.names = c('north','mid','south','east','total'))
a
```

<br/>calculate the chi-squared is 7.96119
```{r}
exp_blue=c(103*78/300,103*73/300,103*76/300,103*73/300)
exp_green=c(115*78/300,115*73/300,115*76/300,115*73/300)
exp_white=c(82*78/300,82*73/300,82*76/300,82*73/300)
exp=data.frame(exp_blue,exp_green,exp_white,row.names = c('north','mid','south','east' ))
exp
a=a[1:4,1:3];a
chi=(a-exp)^2/exp;chi
chi=sum(chi)
chi
```
<br/>step.3 find the p-value is 0.2409604
```{r}
nrow=4
ncol=3
df=(nrow-1)*(ncol-1)
p.value=1-pchisq(chi,df=df)
p.value
```
<br/>step.4 under 95% confidence level the alpha=0.05,**the p-value is larger than alpha, so we cannot reject null hypothesis**
<br/>step.5 **so we can say that 支持傾向在不同區域沒有差異**

###(2)
####北部
```{r}
groups=c("blue","green","white")
times=c(28,30,20)
expected=c((1/3)*78,(1/3)*78,(1/3)*78)
a=data.frame(groups,times,expected)
a
```
<br/>step.1 <br/>$H_0:$ 三個政黨支持度相同$p_1= p_2= p_3$
<br/>$H_a:$ 三個政黨支持度不同$p_1 \neq p_2 \neq p_3$
<br/>p means 政黨支持度

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5,we calculate the chi-square is 2.153846
```{r}
c=a[,2]
exp=a[,3]
chi=((c-exp)^2)/exp
chi=sum(chi)
chi
```
<br/>step.3<br/>the degree of freedom is 2<br/>the p-value is 0.340642
```{r}
k=3
df=k-1;df
p.value=1-pchisq(chi,df=df)
p.value
```

<br/>step.4 under the confidence level of 95% we get the $\alpha=0.05$ ,**the p-value is larger than alpha, so we cannot reject null hypothesis**
<br/>step.5 **so we can say that支持傾向在北部區域沒有差異**

####中部
```{r}
groups=c("blue","green","white")
times=c(26,25,22)
expected=c((1/3)*73,(1/3)*73,(1/3)*73)
a=data.frame(groups,times,expected)
a
```
<br/>step.1 <br/>$H_0:$ 三個政黨支持度相同$p_1= p_2= p_3$
<br/>$H_a:$ 三個政黨支持度不同$p_1 \neq p_2 \neq p_3$
<br/>p means 政黨支持度

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5,we calculate the chi-square is 0.3561644
```{r}
c=a[,2]
exp=a[,3]
chi=((c-exp)^2)/exp
chi=sum(chi)
chi
```
<br/>step.3<br/>the degree of freedom is 2<br/>the p-value is 0.8368736
```{r}
k=3
df=k-1;df
p.value=1-pchisq(chi,df=df)
p.value
```

<br/>step.4 under the confidence level of 95% we get the $\alpha=0.05$ ,**the p-value is larger than alpha, so we cannot reject null hypothesis**
<br/>step.5 **so we can say that支持傾向在中部區域沒有差異**

####南部
```{r}
groups=c("blue","green","white")
times=c(23,38,15)
expected=c((1/3)*76,(1/3)*76,(1/3)*76)
a=data.frame(groups,times,expected)
a
```
<br/>step.1 <br/>$H_0:$ 三個政黨支持度相同$p_1= p_2= p_3$
<br/>$H_a:$ 三個政黨支持度不同$p_1 \neq p_2 \neq p_3$
<br/>p means 政黨支持度

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5,we calculate the chi-square is 10.76316
```{r}
c=a[,2]
exp=a[,3]
chi=((c-exp)^2)/exp
chi=sum(chi)
chi
```
<br/>step.3<br/>the degree of freedom is 2<br/>the p-value is 0.004600552
```{r}
k=3
df=k-1;df
p.value=1-pchisq(chi,df=df)
p.value
```

<br/>step.4 under the confidence level of 95% we get the $\alpha=0.05$ ,**the p-value is smaller than alpha, so we can reject null hypothesis**
<br/>step.5 **so we can say that支持傾向在南部區域有差異**

####東部
```{r}
groups=c("blue","green","white")
times=c(26,22,25)
expected=c((1/3)*73,(1/3)*73,(1/3)*73)
a=data.frame(groups,times,expected)
a
```
<br/>step.1 <br/>$H_0:$ 三個政黨支持度相同$p_1= p_2= p_3$
<br/>$H_a:$ 三個政黨支持度不同$p_1 \neq p_2 \neq p_3$
<br/>p means 政黨支持度

<br/>step.2 the sample is big enough, all of them are bigger than 1, and at least 80% of them bigger than 5,we calculate the chi-square is 0.3561644
```{r}
c=a[,2]
exp=a[,3]
chi=((c-exp)^2)/exp
chi=sum(chi)
chi
```
<br/>step.3<br/>the degree of freedom is 2<br/>the p-value is 0.8368736
```{r}
k=3
df=k-1;df
p.value=1-pchisq(chi,df=df)
p.value
```

<br/>step.4 under the confidence level of 95% we get the $\alpha=0.05$ ,**the p-value is larger than alpha, so we cannot reject null hypothesis**
<br/>step.5 **so we can say that支持傾向在東部區域沒有差異**
<br/>**政黨支持傾向只有在南部有明顯差異**


